{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f10b99f",
   "metadata": {},
   "source": [
    "# Begin of ADM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f0789f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbs4\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbs4\u001b[39;00m \u001b[39mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7a493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ca38d01",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110bebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('Places_url.txt', 'x') as f:\n",
    "    for i in tqdm(range(1,401)):             \n",
    "        url = f'https://www.atlasobscura.com/places?page={i}&sort=likes_count'\n",
    "        result = requests.get(url)\n",
    "        soup = BeautifulSoup(result.text)\n",
    "        matches = soup.find_all(\"a\", {\"class\": \"content-card content-card-place\"})\n",
    "        for match in matches:\n",
    "            f.write(match['href'] + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac183e",
   "metadata": {},
   "source": [
    "### 1.2. Crawl places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(f'Locations')\n",
    "places_url = pd.read_csv('Places_url.txt', header=None)\n",
    "\n",
    "\n",
    "for page in tqdm(range(0,400)):\n",
    "    os.mkdir(f'Locations/page_{page + 1}')\n",
    "    for loc in range(0,18):\n",
    "        with open(f'Locations/page_{page + 1}/location_{(18 * page) + loc + 1}.html', 'x', encoding=\"utf-8\") as f:\n",
    "            url = 'https://www.atlasobscura.com' + places_url.iloc[(18 * page) + loc][0]\n",
    "            result = requests.get(url)\n",
    "            html = result.text\n",
    "            f.write(html)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811aa60",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bf3352bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example not NA\n",
    "url = 'https://www.atlasobscura.com/places/highgate-cemetery'\n",
    "index = requests.get(url)\n",
    "soup = BeautifulSoup(index.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc13286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA presence\n",
    "url = 'https://www.atlasobscura.com/places/gjain-thjorsardalur'\n",
    "index = requests.get(url)\n",
    "soup = BeautifulSoup(index.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# put it on the 'import' cell â˜º\n",
    "# and please check BeautifulSoup or bs and put them in the say way\n",
    "# THANKS!\n",
    "\n",
    "\n",
    "# 7)\n",
    "\n",
    "placeNearby = [match.text for match in soup.find_all('div', {'class': 'DDPageSiderailRecirc__item-title'})]\n",
    "if placeNearby == []:\n",
    "    placeNearby = ''\n",
    "\n",
    "    \n",
    "# 8)\n",
    "\n",
    "match = soup.find_all(\"address\", {\"class\":\"DDPageSiderail__address\"})\n",
    "if match == []:\n",
    "    placeAddress = ''\n",
    "else:\n",
    "    a = match[0].find('div').contents[0:5:2]\n",
    "    placeAddress = \" \".join(a)  \n",
    "\n",
    "\n",
    "# 9)\n",
    "# ask for int but are coordinate are float\n",
    "\n",
    "match = soup.find_all(\"div\", {\"class\":\"DDPageSiderail__coordinates js-copy-coordinates\"})\n",
    "if match != []:\n",
    "    match = match[0].get_text().split()\n",
    "    placeAlt, placeLong = float(match[0][:-1]), float(match[1])\n",
    "else: \n",
    "    placeAlt, placeLong = '', ''\n",
    "\n",
    "\n",
    "# 10)\n",
    "\n",
    "placeEditors = [match.text.strip() for match in soup.find_all(\"a\", {'class' : \"DDPContributorsList__contributor\"})]\n",
    "if placeEditors == []:\n",
    "    placeEditors = ''\n",
    "    \n",
    "\n",
    "# 11)\n",
    "\n",
    "date = soup.find_all(\"div\", {\"class\":\"DDPContributor__name\"})\n",
    "if date != []:\n",
    "    date = date[0].text\n",
    "    placePubDate = datetime.strptime(date, '%B %d, %Y')\n",
    "else:\n",
    "    placePubDate = ''\n",
    "\n",
    "\n",
    "# 12)\n",
    "    \n",
    "a = soup.find_all('div', {\"data-gtm-template\" : \"DDP Footer Recirc Lists\"})\n",
    "if a != []:\n",
    "    placeRelatedLists = [match.text.strip() for match in a[0].find_all('h3')]\n",
    "else: \n",
    "    placeRelatedLists = ''\n",
    "    \n",
    "\n",
    "# 13)\n",
    "\n",
    "matches = soup.find_all(\"div\", {'data-gtm-template': \"DDP Footer Recirc Related\"})\n",
    "if matches == []:\n",
    "    placeRelatedPlaces = ''\n",
    "else:\n",
    "    matches = matches[0].find_all('h3', {'class':\"Card__heading --content-card-v2-title js-title-content\"})\n",
    "    placeRelatedPlaces = [match.text.strip() for match in matches]\n",
    "    \n",
    "    \n",
    "    \n",
    "# 14)\n",
    "\n",
    "url = soup.find_all(\"link\", {'rel':'canonical'})\n",
    "if url != []:\n",
    "    placeURL = url[0]['href']\n",
    "else:\n",
    "    placeURL = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "773286f42bdafd8588749582ed653d25b280a530e585f5f155cb0082e5f8cdaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
