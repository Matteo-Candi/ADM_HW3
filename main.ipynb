{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3W5jGI5PHoQ"
   },
   "source": [
    "# **Homework 3 - Places of the world**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7QLejQIgkLJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from collections import Counter\n",
    "from numpy.linalg import norm \n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "import random as rdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import string\n",
    "import pickle\n",
    "import nltk\n",
    "import bs4\n",
    "import os\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSLgf_UR-UtC"
   },
   "source": [
    "## **1. Data collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OcBNHQk-Uqo"
   },
   "source": [
    "### 1.1. Get the list of places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MWcaQ6G-inm"
   },
   "outputs": [],
   "source": [
    "with open('Places_url.txt', 'x') as f:\n",
    "    for i in tqdm(range(1,401)):             \n",
    "        url = f'https://www.atlasobscura.com/places?page={i}&sort=likes_count'\n",
    "        result = requests.get(url)\n",
    "        soup = bs(result.text)\n",
    "        matches = soup.find_all(\"a\", {\"class\": \"content-card content-card-place\"})\n",
    "        for match in matches:\n",
    "            f.write(match['href'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-8gNTOy-UmR"
   },
   "source": [
    "### 1.2. Crawl places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IOF2jT5-jmz",
    "outputId": "5be815ca-b9e5-4a7a-902d-21d5157c2ec0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:33<00:00, 10.44s/it]\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(f'Locations')\n",
    "places_url = pd.read_csv(os.getcwd()+'/Places_url.txt', header=None)\n",
    "\n",
    "\n",
    "for page in tqdm(range(0,400)):\n",
    "    os.mkdir(f'Locations/page_{page + 1}')\n",
    "    for loc in range(0,18):\n",
    "        with open(os.getcwd()+'/Locations/page_'+str(page+1)+'/location_'+str(18*page+loc+1)+'.html', 'w', encoding=\"utf-8\") as f:\n",
    "            url = 'https://www.atlasobscura.com' + places_url.iloc[(18 * page) + loc][0]\n",
    "            result = requests.get(url)\n",
    "            html = result.text\n",
    "            f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fw2o9DTH-UkN"
   },
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFPTFkld-nq3"
   },
   "outputs": [],
   "source": [
    "# Get all the data for one place in a dataframe\n",
    "# input : String corresponding to the html_file\n",
    "# output : dataframe containing all the data scraped \n",
    "def get_data_for_one_place(html_file):\n",
    "\n",
    "    soup = bs(html_file)\n",
    "\n",
    "    df = pd.DataFrame(columns=['placeName','placeTags','numPeopleVisited','numPeopleWant','placeDesc','placeShortDesc','placeNearby','placeAddress','placeAlt','placeLong','placeEditors','placePubDate','placeRelatedLists','placeRelatedPlaces','placeURL']) \n",
    "\n",
    "    placeName = soup.find('h1', {'class':'DDPage__header-title'})\n",
    "    if placeName is not None :\n",
    "        df['placeName'] = [placeName.text]\n",
    "    else :\n",
    "        df['placeName'] = ''\n",
    "\n",
    "    placeTags = soup.find('div', {'class':'DDPage__header-place-location'})\n",
    "    if placeTags is not None :\n",
    "        df['placeTags'] = placeTags.text\n",
    "    else :\n",
    "        df['placeTags'] = ''\n",
    "\n",
    "    L = soup.find_all('div', {'class':'col-xs-4X js-submit-wrap js-been-to-top-wrap action-btn-col hidden-print'})\n",
    "    if L is not None and len(L)!=0 and L[0].find('div', {'class':'title-md item-action-count'}) is not None :\n",
    "        df['numPeopleVisited'] = int(L[0].find('div', {'class':'title-md item-action-count'}).text)\n",
    "    else :\n",
    "        df['numPeopleVisited'] = ''\n",
    "\n",
    "    L = soup.find_all('div', {'class':'col-xs-4X js-submit-wrap js-like-top-wrap action-btn-col hidden-print'})  \n",
    "    if L is not None and len(L)!=0 and L[0].find('div', {'class':'title-md item-action-count'}) is not None :\n",
    "        df['numPeopleWant'] = int(L[0].find('div', {'class':'title-md item-action-count'}).text)\n",
    "    else :\n",
    "        df['numPeopleWant'] = ''\n",
    "\n",
    "    placeDesc = soup.find('div', {'id':'place-body'})\n",
    "    if placeDesc is not None :\n",
    "        df['placeDesc'] = placeDesc.text.replace('\\n',' ').replace(u'\\xa0',u' ')\n",
    "    else :\n",
    "        df['placeDesc'] = ''\n",
    "    \n",
    "    placeShortDesc = soup.find('h3', {'class': 'DDPage__header-dek'})\n",
    "    if placeShortDesc is not None :\n",
    "        df['placeShortDesc'] = placeShortDesc.text.replace('\\n',' ').replace(u'\\xa0',u' ')\n",
    "    else :\n",
    "        df['placeShortDesc'] = ''\n",
    "\n",
    "    placeNearby = set([match.text for match in soup.find_all('div', {'class': 'DDPageSiderailRecirc__item-title'})])\n",
    "    if len(placeNearby) != 0 :\n",
    "        df['placeNearby'] = ','.join(list(placeNearby))\n",
    "    else :\n",
    "        df['placeNearby'] = ''\n",
    "\n",
    "    match_address = soup.find(\"address\", {\"class\":\"DDPageSiderail__address\"})\n",
    "    if match_address is not None :\n",
    "        placeAddress = match_address.find('div').contents[0:5:2]\n",
    "        df['placeAddress'] = \"\".join(placeAddress).replace('\\n','')\n",
    "    else :\n",
    "        df['placeAddress'] = ''\n",
    "\n",
    "    match = soup.find(\"div\", {\"class\":\"DDPageSiderail__coordinates js-copy-coordinates\"})\n",
    "    if match is not None :\n",
    "        match = match.get_text().split()\n",
    "        df['placeAlt'] = float(match[0][:-1])\n",
    "        df['placeLong'] = float(match[1])\n",
    "    else :\n",
    "        df['placeAlt'] = ''\n",
    "        df['placeLong'] = ''\n",
    "\n",
    "    contributors = []\n",
    "    for contributor in soup.find_all('div', {'class':'DDPContributors'})[0].find_all('a', {'class':'DDPContributorsList__contributor'}) :\n",
    "        if contributor.find('span') is not None :\n",
    "            contributors.append(contributor.find('span').text)\n",
    "        else :\n",
    "            contributors.append(contributor.text)\n",
    "    if len(contributors) != 0 :\n",
    "        df['placeEditors'] = ','.join(list(set(contributors)))\n",
    "    else :\n",
    "        df['placeEditors'] = ''\n",
    "\n",
    "    placePubDate = soup.find(\"div\", {\"class\":\"DDPContributor__name\"})\n",
    "    if placePubDate is not None :\n",
    "        df['placePubDate'] = datetime.strptime(placePubDate.text, '%B %d, %Y')\n",
    "    else :\n",
    "        df['placePubDate'] = ''\n",
    "\n",
    "    placeRelatedLists = []\n",
    "    placeRelatedPlaces = []\n",
    "    for container in soup.find_all('div', {'class' : 'full-width-container CardRecircSection'}) :\n",
    "        title = container.find('div', {'class':'CardRecircSection__title'}).text\n",
    "        if 'Appears' in title :\n",
    "            for container_related in container.find_all('h3', {'class':'Card__heading --content-card-v2-title js-title-content'}) :\n",
    "                placeRelatedLists.append(container_related.text[1:-1])\n",
    "        elif 'Related Places' in title :\n",
    "            for container_related in container.find_all('h3', {'class':'Card__heading --content-card-v2-title js-title-content'}) :\n",
    "                placeRelatedPlaces.append(container_related.text[1:-1])\n",
    "    if len(placeRelatedLists) != 0 :\n",
    "        df['placeRelatedLists'] = ','.join(placeRelatedLists)\n",
    "    else :\n",
    "        df['placeRelatedLists'] = ''\n",
    "    if len(placeRelatedPlaces) != 0 :\n",
    "        df['placeRelatedPlaces'] = ','.join(placeRelatedPlaces)\n",
    "    else :\n",
    "        df['placeRelatedPlaces'] = ''\n",
    "\n",
    "    if len(soup.find_all(\"link\", {'rel':'canonical'})) != 0 :\n",
    "        df['placeURL'] = soup.find_all(\"link\", {'rel':'canonical'})[0]['href']   \n",
    "    else :\n",
    "        df['placeURL'] = ''  \n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6H7Z4QxgkLX",
    "outputId": "3b877c79-88dc-47a0-dc9c-34ea9ff1bbb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [28:34<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# We get all the html files contained in the Locations directory\n",
    "# For each html file we call the get_data_for_one_place function\n",
    "# We upload the output of the function in a tsv file\n",
    "\n",
    "for page in tqdm(range(0,400)):\n",
    "    for loc in range(0,18):\n",
    "        with open(os.getcwd()+'/Locations/page_'+str(page+1)+'/location_'+str(18*page+loc+1)+'.html', 'r', encoding=\"utf-8\") as f :\n",
    "            html_file = f.read()\n",
    "        df = get_data_for_one_place(html_file)\n",
    "        df.to_csv(os.getcwd()+'/Locations/page_'+str(page+1)+'/location_'+str(18*page+loc+1)+'.tsv', sep='\\t', index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y05B7aa0-Ufb"
   },
   "source": [
    "---\n",
    "## **2. Search Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sLepkcOgkLa"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stemmers = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "def remove_punctuations(comment) :\n",
    "    comment = re.sub(r'[? | ! | \\' |\" | #]','',comment)\n",
    "    comment = re.sub(r'[. | , | ) | ( | \\ | / ]','',comment)\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MocI2eQz_HTj",
    "outputId": "a781ae83-b7aa-4920-8454-9cd011dc7c5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [01:43<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Mettre les contenus de tous les fichiers tsv dans un seul dataframe\n",
    "# Effectuer un preprocessing sur le champ long description de ce dataframe\n",
    "# Enregistrer ce dataframe dans un fichier tsv à la racine\n",
    "# We want to get the data of all the tsv files and put it in only one tsv file\n",
    "# Before doing it we preprocess all the attributes placeDesc and placeShortDesc of each tsv file\n",
    "\n",
    "def getPreProcessedData(description) :\n",
    "    filtered_data = []\n",
    "    for word in description.split() :\n",
    "        # We remove the puncuations\n",
    "        for clean_word in remove_punctuations(word).split() :\n",
    "            # We check if we have only alpha characters and if the word has a len of 3 at least\n",
    "            if clean_word.isalpha() and len(clean_word) > 2 :\n",
    "                # We check if it's not a stopword\n",
    "                if clean_word.lower() not in stopwords :\n",
    "                    # We apply the stemmatization\n",
    "                    stemmed_word = stemmers.stem(clean_word.lower())\n",
    "                    filtered_data.append(stemmed_word)\n",
    "                else :\n",
    "                    continue\n",
    "            else :\n",
    "                continue\n",
    "    return \" \".join(filtered_data)\n",
    "\n",
    "\n",
    "cols = columns=['placeName','placeTags','numPeopleVisited','numPeopleWant','placeDesc','placeShortDesc','placeNearby','placeAddress','placeAlt','placeLong','placeEditors','placePubDate','placeRelatedLists','placeRelatedPlaces','placeURL']\n",
    "df = pd.DataFrame(columns=cols)\n",
    "for page in tqdm(range(0,400)):\n",
    "    for loc in range(0,18):\n",
    "        df_tsv = pd.read_csv(os.getcwd()+'/Locations/page_'+str(page+1)+'/location_'+str(18*page+loc+1)+'.tsv', sep='\\t', names=cols)\n",
    "        df_tsv.placeDesc = df_tsv.placeDesc.apply(lambda row : getPreProcessedData(row))\n",
    "        df_tsv.placeShortDesc = df_tsv.placeShortDesc.apply(lambda row : getPreProcessedData(row))\n",
    "        df = pd.concat([df,df_tsv])\n",
    "\n",
    "df.to_csv(os.getcwd()+'/locations_data.tsv', sep='\\t', index=False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNybpeyAgkLc",
    "outputId": "93184056-7242-4b52-924a-c1d104ae9efe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeTags</th>\n",
       "      <th>numPeopleVisited</th>\n",
       "      <th>numPeopleWant</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeShortDesc</th>\n",
       "      <th>placeNearby</th>\n",
       "      <th>placeAddress</th>\n",
       "      <th>placeAlt</th>\n",
       "      <th>placeLong</th>\n",
       "      <th>placeEditors</th>\n",
       "      <th>placePubDate</th>\n",
       "      <th>placeRelatedLists</th>\n",
       "      <th>placeRelatedPlaces</th>\n",
       "      <th>placeURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City Hall Station</td>\n",
       "      <td>Manhattan, New York</td>\n",
       "      <td>1828</td>\n",
       "      <td>8583</td>\n",
       "      <td>first new york citi subway built oper interbor...</td>\n",
       "      <td>beauti abandon new york subway station complet...</td>\n",
       "      <td>Tunnel Number 3,African Burial Ground National...</td>\n",
       "      <td>31 Centre StNew York, New York, 10007United St...</td>\n",
       "      <td>40.7134</td>\n",
       "      <td>-74.0046</td>\n",
       "      <td>Allan,erjeffery,fosterc827,offtrackplanet,wyth...</td>\n",
       "      <td>2010-05-08</td>\n",
       "      <td>30 Unexpected Places to Have a Joyful Adventur...</td>\n",
       "      <td>Crystal Palace Subway,Moscow Metro Stations,Ro...</td>\n",
       "      <td>https://www.atlasobscura.com/places/city-hall-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Highgate Cemetery</td>\n",
       "      <td>London, England</td>\n",
       "      <td>2618</td>\n",
       "      <td>8182</td>\n",
       "      <td>open highgat one infam cemeteri origin open on...</td>\n",
       "      <td>london creepiest cemeteri site duel magician m...</td>\n",
       "      <td>Parkland Walk,Dick Whittington’s Cat ,World's ...</td>\n",
       "      <td>Swain's Lane, HighgateLondon, England, N6Unite...</td>\n",
       "      <td>51.5675</td>\n",
       "      <td>-0.1483</td>\n",
       "      <td>gingercinnamon,Annetta Black,lushjay,SEANETTA,...</td>\n",
       "      <td>2014-08-09</td>\n",
       "      <td>The World's Top 100 Wonders in 2018,London's T...</td>\n",
       "      <td>Jewett City Vampires,Tomb of the Mather Family...</td>\n",
       "      <td>https://www.atlasobscura.com/places/highgate-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leadenhall Market</td>\n",
       "      <td>London, England</td>\n",
       "      <td>3135</td>\n",
       "      <td>7570</td>\n",
       "      <td>ornat paint roof cobbl floor leadenhal market ...</td>\n",
       "      <td>ornat victorian marketplac set diagon alley le...</td>\n",
       "      <td>The Cornhill Devils ,Philpot Lane Mice Sculptu...</td>\n",
       "      <td>London, England, EC3VUnited Kingdom</td>\n",
       "      <td>51.5126</td>\n",
       "      <td>-0.0834</td>\n",
       "      <td>Lyloueen,lili,Meg,amiedd,JZA,Gavin,raymondwinn...</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>The Ultimate Guide to Stunning, Surprising, or...</td>\n",
       "      <td>Rivendell,Bagdad Cafe,Gare de la Ciotat,Drvengrad</td>\n",
       "      <td>https://www.atlasobscura.com/places/leadenhall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Wave Organ</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>2429</td>\n",
       "      <td>7408</td>\n",
       "      <td>locat jetti san francisco bay wave organ built...</td>\n",
       "      <td>huge music instrument play ocean</td>\n",
       "      <td>Palace of Fine Arts,Long Now Orrery,The Stern ...</td>\n",
       "      <td>83 Marina Green DrSan Francisco, California, 9...</td>\n",
       "      <td>37.8085</td>\n",
       "      <td>-122.4401</td>\n",
       "      <td>td007,Mark Casey,Chassy,SEANETTA,hana,Saal333,...</td>\n",
       "      <td>2008-11-21</td>\n",
       "      <td>Leonardo Nam's 16 Quirky Roadside Attractions ...</td>\n",
       "      <td>Sea Organ,Silent Green Kulturquartier,St. John...</td>\n",
       "      <td>https://www.atlasobscura.com/places/wave-organ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catacombes de Paris</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>4447</td>\n",
       "      <td>7046</td>\n",
       "      <td>parisian polic assign train exercis previous u...</td>\n",
       "      <td>vast legendari catacomb hold secret much stran...</td>\n",
       "      <td>Arago Medallions,Sculptures de Décure,Jeannot'...</td>\n",
       "      <td>1 Place Denfert-RochereauParis, 75014France</td>\n",
       "      <td>48.8343</td>\n",
       "      <td>2.3322</td>\n",
       "      <td>ramonrodz2212,Fred Cherrygarden,ceasterling,Es...</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>19 Catacombs Sure to Tingle Your Spine,The Wor...</td>\n",
       "      <td>Ossario di San Martino,Leuk Charnel House,Sant...</td>\n",
       "      <td>https://www.atlasobscura.com/places/catacombes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>The Cairo</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>342</td>\n",
       "      <td>405</td>\n",
       "      <td>washington residenti neighborhood typifi low r...</td>\n",
       "      <td>unaccept tall build real reason washington dcs...</td>\n",
       "      <td>Annie's Paramount Steakhouse,House of the Temp...</td>\n",
       "      <td>1615 Q Street NWWashington, District of Columb...</td>\n",
       "      <td>38.9113</td>\n",
       "      <td>-77.0375</td>\n",
       "      <td>Greg Jones,matthewbgilmore,Elliot Carter</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145 Rue Lafayette,Architect of the Capitol Arc...</td>\n",
       "      <td>https://www.atlasobscura.com/places/the-cairo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>Winganon Space Capsule</td>\n",
       "      <td>Talala, Oklahoma</td>\n",
       "      <td>120</td>\n",
       "      <td>405</td>\n",
       "      <td>drive along dull stretch road talala winganon ...</td>\n",
       "      <td>detach cement mixer transform resembl relic ob...</td>\n",
       "      <td>Playtower,Totem Pole Park,Bowling Ball Yard Art</td>\n",
       "      <td>E 300 RoadTalala, OklahomaUnited States</td>\n",
       "      <td>36.5828</td>\n",
       "      <td>-95.6516</td>\n",
       "      <td>5qmbcxnkwy,Darrell Powers,MNtraveler,CoolCrab,...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Folk Art Park,Apple Valley Hillbilly Garden an...</td>\n",
       "      <td>https://www.atlasobscura.com/places/winganon-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7197</th>\n",
       "      <td>Cook &amp; Book</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>124</td>\n",
       "      <td>405</td>\n",
       "      <td>cook book brussel far bookstor size supermarke...</td>\n",
       "      <td>wonder kitsch bookstor size supermarket</td>\n",
       "      <td>Bibliotheca Wittockiana,Temple of Human Passio...</td>\n",
       "      <td>1 Place du Temps LibreWoluwe-Saint-LambertBrus...</td>\n",
       "      <td>50.8480</td>\n",
       "      <td>4.4373</td>\n",
       "      <td>simonlitton,rhumphrey17,Producer Dani</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>The Ultimate Guide to Wondrous Independent Boo...</td>\n",
       "      <td>For Keeps Bookstore,Fantagraphics,La Llama,Whi...</td>\n",
       "      <td>https://www.atlasobscura.com/places/cook-book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7198</th>\n",
       "      <td>Xul Solar Museum</td>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>129</td>\n",
       "      <td>405</td>\n",
       "      <td>dream reform perfect univers argentin artist x...</td>\n",
       "      <td>xul solar artist altern world inventor languag...</td>\n",
       "      <td>El Ateneo Grand Splendid,Ricardo Rojas House M...</td>\n",
       "      <td>Laprida 1212Buenos AiresArgentina</td>\n",
       "      <td>-34.5948</td>\n",
       "      <td>-58.4078</td>\n",
       "      <td>Allison</td>\n",
       "      <td>2016-09-12</td>\n",
       "      <td>A Linguistics Lover's Tour of the World</td>\n",
       "      <td>Blenko Man,Ilana Goor Museum ,Museo de Arte Po...</td>\n",
       "      <td>https://www.atlasobscura.com/places/xul-solar-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>Termesphere Gallery</td>\n",
       "      <td>Spearfish, South Dakota</td>\n",
       "      <td>71</td>\n",
       "      <td>406</td>\n",
       "      <td>artist paint flat plane termespher galleri art...</td>\n",
       "      <td>geodes galleri hold collect paint sphere make ...</td>\n",
       "      <td>Mt. Moriah Cemetery,Fish Car No. 3,Mount Roose...</td>\n",
       "      <td>1920 Christensen DriveSpearfish, South Dakota,...</td>\n",
       "      <td>44.4574</td>\n",
       "      <td>-103.8258</td>\n",
       "      <td>kgsn143</td>\n",
       "      <td>2014-08-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Museo del Barro (Museum of Clay),Museo Dolores...</td>\n",
       "      <td>https://www.atlasobscura.com/places/termespher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7200 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   placeName                  placeTags  numPeopleVisited  \\\n",
       "0          City Hall Station        Manhattan, New York              1828   \n",
       "1          Highgate Cemetery            London, England              2618   \n",
       "2          Leadenhall Market            London, England              3135   \n",
       "3             The Wave Organ  San Francisco, California              2429   \n",
       "4        Catacombes de Paris              Paris, France              4447   \n",
       "...                      ...                        ...               ...   \n",
       "7195               The Cairo           Washington, D.C.               342   \n",
       "7196  Winganon Space Capsule           Talala, Oklahoma               120   \n",
       "7197             Cook & Book          Brussels, Belgium               124   \n",
       "7198        Xul Solar Museum    Buenos Aires, Argentina               129   \n",
       "7199     Termesphere Gallery    Spearfish, South Dakota                71   \n",
       "\n",
       "      numPeopleWant                                          placeDesc  \\\n",
       "0              8583  first new york citi subway built oper interbor...   \n",
       "1              8182  open highgat one infam cemeteri origin open on...   \n",
       "2              7570  ornat paint roof cobbl floor leadenhal market ...   \n",
       "3              7408  locat jetti san francisco bay wave organ built...   \n",
       "4              7046  parisian polic assign train exercis previous u...   \n",
       "...             ...                                                ...   \n",
       "7195            405  washington residenti neighborhood typifi low r...   \n",
       "7196            405  drive along dull stretch road talala winganon ...   \n",
       "7197            405  cook book brussel far bookstor size supermarke...   \n",
       "7198            405  dream reform perfect univers argentin artist x...   \n",
       "7199            406  artist paint flat plane termespher galleri art...   \n",
       "\n",
       "                                         placeShortDesc  \\\n",
       "0     beauti abandon new york subway station complet...   \n",
       "1     london creepiest cemeteri site duel magician m...   \n",
       "2     ornat victorian marketplac set diagon alley le...   \n",
       "3                      huge music instrument play ocean   \n",
       "4     vast legendari catacomb hold secret much stran...   \n",
       "...                                                 ...   \n",
       "7195  unaccept tall build real reason washington dcs...   \n",
       "7196  detach cement mixer transform resembl relic ob...   \n",
       "7197            wonder kitsch bookstor size supermarket   \n",
       "7198  xul solar artist altern world inventor languag...   \n",
       "7199  geodes galleri hold collect paint sphere make ...   \n",
       "\n",
       "                                            placeNearby  \\\n",
       "0     Tunnel Number 3,African Burial Ground National...   \n",
       "1     Parkland Walk,Dick Whittington’s Cat ,World's ...   \n",
       "2     The Cornhill Devils ,Philpot Lane Mice Sculptu...   \n",
       "3     Palace of Fine Arts,Long Now Orrery,The Stern ...   \n",
       "4     Arago Medallions,Sculptures de Décure,Jeannot'...   \n",
       "...                                                 ...   \n",
       "7195  Annie's Paramount Steakhouse,House of the Temp...   \n",
       "7196    Playtower,Totem Pole Park,Bowling Ball Yard Art   \n",
       "7197  Bibliotheca Wittockiana,Temple of Human Passio...   \n",
       "7198  El Ateneo Grand Splendid,Ricardo Rojas House M...   \n",
       "7199  Mt. Moriah Cemetery,Fish Car No. 3,Mount Roose...   \n",
       "\n",
       "                                           placeAddress  placeAlt  placeLong  \\\n",
       "0     31 Centre StNew York, New York, 10007United St...   40.7134   -74.0046   \n",
       "1     Swain's Lane, HighgateLondon, England, N6Unite...   51.5675    -0.1483   \n",
       "2                   London, England, EC3VUnited Kingdom   51.5126    -0.0834   \n",
       "3     83 Marina Green DrSan Francisco, California, 9...   37.8085  -122.4401   \n",
       "4           1 Place Denfert-RochereauParis, 75014France   48.8343     2.3322   \n",
       "...                                                 ...       ...        ...   \n",
       "7195  1615 Q Street NWWashington, District of Columb...   38.9113   -77.0375   \n",
       "7196            E 300 RoadTalala, OklahomaUnited States   36.5828   -95.6516   \n",
       "7197  1 Place du Temps LibreWoluwe-Saint-LambertBrus...   50.8480     4.4373   \n",
       "7198                  Laprida 1212Buenos AiresArgentina  -34.5948   -58.4078   \n",
       "7199  1920 Christensen DriveSpearfish, South Dakota,...   44.4574  -103.8258   \n",
       "\n",
       "                                           placeEditors placePubDate  \\\n",
       "0     Allan,erjeffery,fosterc827,offtrackplanet,wyth...   2010-05-08   \n",
       "1     gingercinnamon,Annetta Black,lushjay,SEANETTA,...   2014-08-09   \n",
       "2     Lyloueen,lili,Meg,amiedd,JZA,Gavin,raymondwinn...   2016-08-01   \n",
       "3     td007,Mark Casey,Chassy,SEANETTA,hana,Saal333,...   2008-11-21   \n",
       "4     ramonrodz2212,Fred Cherrygarden,ceasterling,Es...   2009-02-13   \n",
       "...                                                 ...          ...   \n",
       "7195           Greg Jones,matthewbgilmore,Elliot Carter   2017-09-12   \n",
       "7196  5qmbcxnkwy,Darrell Powers,MNtraveler,CoolCrab,...   2017-08-14   \n",
       "7197              simonlitton,rhumphrey17,Producer Dani   2017-02-08   \n",
       "7198                                            Allison   2016-09-12   \n",
       "7199                                            kgsn143   2014-08-19   \n",
       "\n",
       "                                      placeRelatedLists  \\\n",
       "0     30 Unexpected Places to Have a Joyful Adventur...   \n",
       "1     The World's Top 100 Wonders in 2018,London's T...   \n",
       "2     The Ultimate Guide to Stunning, Surprising, or...   \n",
       "3     Leonardo Nam's 16 Quirky Roadside Attractions ...   \n",
       "4     19 Catacombs Sure to Tingle Your Spine,The Wor...   \n",
       "...                                                 ...   \n",
       "7195                                                NaN   \n",
       "7196                                                NaN   \n",
       "7197  The Ultimate Guide to Wondrous Independent Boo...   \n",
       "7198            A Linguistics Lover's Tour of the World   \n",
       "7199                                                NaN   \n",
       "\n",
       "                                     placeRelatedPlaces  \\\n",
       "0     Crystal Palace Subway,Moscow Metro Stations,Ro...   \n",
       "1     Jewett City Vampires,Tomb of the Mather Family...   \n",
       "2     Rivendell,Bagdad Cafe,Gare de la Ciotat,Drvengrad   \n",
       "3     Sea Organ,Silent Green Kulturquartier,St. John...   \n",
       "4     Ossario di San Martino,Leuk Charnel House,Sant...   \n",
       "...                                                 ...   \n",
       "7195  145 Rue Lafayette,Architect of the Capitol Arc...   \n",
       "7196  Folk Art Park,Apple Valley Hillbilly Garden an...   \n",
       "7197  For Keeps Bookstore,Fantagraphics,La Llama,Whi...   \n",
       "7198  Blenko Man,Ilana Goor Museum ,Museo de Arte Po...   \n",
       "7199  Museo del Barro (Museum of Clay),Museo Dolores...   \n",
       "\n",
       "                                               placeURL  \n",
       "0     https://www.atlasobscura.com/places/city-hall-...  \n",
       "1     https://www.atlasobscura.com/places/highgate-c...  \n",
       "2     https://www.atlasobscura.com/places/leadenhall...  \n",
       "3        https://www.atlasobscura.com/places/wave-organ  \n",
       "4     https://www.atlasobscura.com/places/catacombes...  \n",
       "...                                                 ...  \n",
       "7195  https://www.atlasobscura.com/places/the-cairo-...  \n",
       "7196  https://www.atlasobscura.com/places/winganon-s...  \n",
       "7197      https://www.atlasobscura.com/places/cook-book  \n",
       "7198  https://www.atlasobscura.com/places/xul-solar-...  \n",
       "7199  https://www.atlasobscura.com/places/termespher...  \n",
       "\n",
       "[7200 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the full dataset of places with placeDesc and placeShortDesc preprocessed.\n",
    "df_out = pd.read_csv(os.getcwd()+'/locations_data.tsv', sep='\\t')\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAp4yrzH-Ucq"
   },
   "source": [
    "### 2.1. Conjunctive query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZG77zGj_LaE"
   },
   "source": [
    " 2.1.1) Create your index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_a3LB9vUgkLe"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('locations_data.tsv', sep='\\t')\n",
    "data = df.placeDesc\n",
    "\n",
    "splitted_rows = data.apply(lambda row: row.split())\n",
    "vocabulary = list(set([i for row in splitted_rows for i in set(row)]))          # vocabulary as a sorted list of words\n",
    "vocabulary.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUNOYsT9gkLe"
   },
   "outputs": [],
   "source": [
    "inverted_index_1 = {}\n",
    "for i, word in tqdm(enumerate(vocabulary)):\n",
    "    inverted_index_1[i] = list(splitted_rows[splitted_rows.apply(lambda row: word in row)].index)\n",
    "\n",
    "# we have saved in and external file the inverted_index_1 to not compute it everytime. We import the dictionary in the function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBhdTOgE_Yzo"
   },
   "source": [
    "2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "h4vsDwzW_Ysa"
   },
   "outputs": [],
   "source": [
    "# creating a function that requires as input our dataframe and the query to simulate a search engine\n",
    "\n",
    "def search_engine_1(dataframe, query):\n",
    "\n",
    "    data = dataframe.placeDesc\n",
    "\n",
    "    splitted_rows = data.apply(lambda row: row.split())\n",
    "    vocabulary = list(set([i for row in splitted_rows for i in set(row)]))\n",
    "    vocabulary.sort()                                                           # vocabulary as a sorted list of words\n",
    "\n",
    "    query_split = query.split()\n",
    "    stemmers = nltk.stem.SnowballStemmer('english')\n",
    "    stemmed_query = [stemmers.stem(word.lower()) for word in query_split]       # stemming the query words\n",
    "\n",
    "    id_query_words = [vocabulary.index(word) for word in stemmed_query]         # vocabulary indexs of the query's words\n",
    "    inverted_index_1 = pickle.load(open('inverted_index_1.pkl', 'rb'))\n",
    "    docs = [inverted_index_1[str(id)] for id in id_query_words]                 # documents that match with the query\n",
    "\n",
    "    matches = list(reduce(lambda x,y: set(x).intersection(y), docs))            # documents that contain all query's word\n",
    "    matches.sort()\n",
    "    \n",
    "    output = dataframe[['placeName', 'placeDesc', 'placeURL']]\n",
    "    output.columns = ['Title', 'Description', 'Url']\n",
    "    output.isetitem(2, [row[28:] for row in output.Url])\n",
    "    print(f\"\\n Query: {query} \\n\")\n",
    "    display(output.loc[matches[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "xNUDsUiugkLg",
    "outputId": "00bad833-a881-4e5d-9b2a-97d2418578ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: american museum \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>The Witch House of Salem</td>\n",
       "      <td>salem witchcraft trial took place februari may...</td>\n",
       "      <td>/places/witch-house-salem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Museum of the Weird</td>\n",
       "      <td>dime dime store museum account endang speci fi...</td>\n",
       "      <td>/places/museum-weird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>National Atomic Testing Museum</td>\n",
       "      <td>las vega oasi desert one sleep everi vice imag...</td>\n",
       "      <td>/places/national-atomic-testing-museum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Canyons of the Ancients</td>\n",
       "      <td>ripe quiet reflect simpli canyon ancient outdo...</td>\n",
       "      <td>/places/canyons-of-the-ancients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>The Natural Bridge</td>\n",
       "      <td>often cite place among great wonder natur worl...</td>\n",
       "      <td>/places/the-natural-bridge-natural-bridge-virg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Uncommon Objects</td>\n",
       "      <td>like eleg antiqu mall gone horribl wrong diffe...</td>\n",
       "      <td>/places/uncommon-objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>KattenKabinet</td>\n",
       "      <td>death pet inspir number reaction rare anyon ta...</td>\n",
       "      <td>/places/kattenkabinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>CDC Museum</td>\n",
       "      <td>hit film outbreak resid unit state come terror...</td>\n",
       "      <td>/places/cdc-museum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>Petra</td>\n",
       "      <td>built sometim capit citi nabataean semit peopl...</td>\n",
       "      <td>/places/petra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Maryhill Museum and Stonehenge</td>\n",
       "      <td>sam odd express origin unclear date back least...</td>\n",
       "      <td>/places/maryhill-museum-and-stonehenge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "59         The Witch House of Salem   \n",
       "141             Museum of the Weird   \n",
       "173  National Atomic Testing Museum   \n",
       "224         Canyons of the Ancients   \n",
       "320              The Natural Bridge   \n",
       "329                Uncommon Objects   \n",
       "356                   KattenKabinet   \n",
       "360                      CDC Museum   \n",
       "415                           Petra   \n",
       "690  Maryhill Museum and Stonehenge   \n",
       "\n",
       "                                           Description  \\\n",
       "59   salem witchcraft trial took place februari may...   \n",
       "141  dime dime store museum account endang speci fi...   \n",
       "173  las vega oasi desert one sleep everi vice imag...   \n",
       "224  ripe quiet reflect simpli canyon ancient outdo...   \n",
       "320  often cite place among great wonder natur worl...   \n",
       "329  like eleg antiqu mall gone horribl wrong diffe...   \n",
       "356  death pet inspir number reaction rare anyon ta...   \n",
       "360  hit film outbreak resid unit state come terror...   \n",
       "415  built sometim capit citi nabataean semit peopl...   \n",
       "690  sam odd express origin unclear date back least...   \n",
       "\n",
       "                                                   Url  \n",
       "59                           /places/witch-house-salem  \n",
       "141                               /places/museum-weird  \n",
       "173             /places/national-atomic-testing-museum  \n",
       "224                    /places/canyons-of-the-ancients  \n",
       "320  /places/the-natural-bridge-natural-bridge-virg...  \n",
       "329                           /places/uncommon-objects  \n",
       "356                              /places/kattenkabinet  \n",
       "360                                 /places/cdc-museum  \n",
       "415                                      /places/petra  \n",
       "690             /places/maryhill-museum-and-stonehenge  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This first search engine returns the best 10 matches simply sorted as on the website\n",
    "\n",
    "search_engine_1(df, 'american museum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU03Hu7F_YkW"
   },
   "source": [
    "### 2.2. Conjunctive query & Ranking score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaSGQdg5_YPV"
   },
   "source": [
    "2.2.1) Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zlbTlmTxgkLh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('locations_data.tsv', sep='\\t')\n",
    "data = df.placeDesc\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)                                # tf-idf for all the words in all the documents\n",
    "tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(data).todense()\n",
    "\n",
    "vocabulary = tfidf_vectorizer.vocabulary_                                       # vocabulary that match every word with a specific index\n",
    "ifidf_table = pd.DataFrame(tfidf_vectorizer_vectors)\n",
    "n, m = ifidf_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA_6ncRi_YF4"
   },
   "outputs": [],
   "source": [
    "inverted_index_2 = {}\n",
    "for word in tqdm(range(m)):\n",
    "    inverted_index_2[word] = [(doc, ifidf_table[word].loc[doc]) for doc in range(n) if ifidf_table[word].loc[doc] != 0]\n",
    "\n",
    "# we have saved in and external file the inverted_index_1 to not compute it everytime. We import the dictionary in the function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyJps-s4_2iR"
   },
   "source": [
    "2.2.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "zoJTmwoU_2bZ"
   },
   "outputs": [],
   "source": [
    "# creating the function to compute the cosine similarity between the query and the documents\n",
    "\n",
    "def cosine_similarity(q, d):\n",
    "    value = np.dot(q, d) / (norm(q) * norm(d))\n",
    "    return value.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "bmxCCE9NgkLi"
   },
   "outputs": [],
   "source": [
    "# creating a function that requires as input our dataframe, the query and the number of top-match to show\n",
    "# simulating a search engine\n",
    "\n",
    "def search_engine_2(dataframe, query, k):\n",
    "    \n",
    "    data = dataframe.placeDesc\n",
    "\n",
    "    query_split = query.split()\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')                                                  \n",
    "    stemmers = nltk.stem.SnowballStemmer('english')\n",
    "    stemmed_query = [stemmers.stem(word.lower()) for word in query_split if word not in stopwords]      # cleaning th query with stemming and removing stopwords\n",
    "    new_query = [' '.join(stemmed_query)]\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True)                                                    \n",
    "    tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(data).todense()                           # tf-idf table (documents x words)\n",
    "    query_vector = tfidf_vectorizer.transform(new_query)                                                # vector q of query's tfidf\n",
    "\n",
    "    vocabulary = tfidf_vectorizer.vocabulary_                                                           # vocabulary that match every word with a specific index\n",
    "\n",
    "    inverted_index_2 = pickle.load(open('inverted_index_2.pkl', 'rb'))                                  # uploading inverted_index_2 previously getted\n",
    "\n",
    "    for word in stemmed_query:\n",
    "        if word not in vocabulary:\n",
    "            return 'No places found!'\n",
    "    id_query_words = list(dict.fromkeys([vocabulary[word] for word in stemmed_query]))                  # ids of words in the query\n",
    "\n",
    "    docs = [inverted_index_2[id] for id in id_query_words]\n",
    "    docs_list = [[x[0] for x in l] for l in docs]                                                       # list the documents that contain query words\n",
    "\n",
    "    matches = list(reduce(lambda x,y: set(x).intersection(y), docs_list))                               # documents that contain all query words\n",
    "    doc_vector = [[item[1]  for doc in docs for item in doc if item[0] == match] for match in matches]  # list with all matched documents with tf-idf values\n",
    "    query_vector = [query_vector.toarray()[0][idx] for idx in id_query_words] \n",
    "\n",
    "    cosine_values = [cosine_similarity(query_vector, doc) for doc in doc_vector]                        # cosine similarity with query and all documents matched\n",
    "    doc_cosine = list(zip(matches,cosine_values))\n",
    "    doc_cosine_sort_by_index = sorted(doc_cosine, key=lambda tup: tup[0])                               # cosine similarity list sorted by index\n",
    "    doc_cosine_sort_by_value = sorted(doc_cosine, key=lambda tup: (tup[1], -tup[0]), reverse=True)      # cosine similarity list sorted by value and index\n",
    "\n",
    "    output = df[['placeName', 'placeDesc', 'placeURL']].loc[[x[0] for x in doc_cosine_sort_by_index]]   # dataframe with affected columns and rows\n",
    "    output.columns = ['Title', 'Description', 'Url']\n",
    "    output.isetitem(2, [row[28:] for row in output.Url])\n",
    "    output['Similarity'] = [y[1] for y in doc_cosine_sort_by_index]                                     # similarity column\n",
    "    print(f\"\\n Query: {query} \\n\")\n",
    "    display(output.loc[[x[0] for x in doc_cosine_sort_by_value[:k]]]) \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "gC2W-ESygkLj",
    "outputId": "9b967b86-bf2d-4374-b3fe-4ca003a31f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: american museum \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>The Athenian Agora</td>\n",
       "      <td>lie right beneath northern slope acropoli anci...</td>\n",
       "      <td>/places/the-athenian-agora-athens-greece</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5958</th>\n",
       "      <td>Old Stone Fort</td>\n",
       "      <td>confluenc big littl duck river near manchest t...</td>\n",
       "      <td>/places/old-stone-fort-state-archaeological-park</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>The Witch House of Salem</td>\n",
       "      <td>salem witchcraft trial took place februari may...</td>\n",
       "      <td>/places/witch-house-salem</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Uncommon Objects</td>\n",
       "      <td>like eleg antiqu mall gone horribl wrong diffe...</td>\n",
       "      <td>/places/uncommon-objects</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>Albertine</td>\n",
       "      <td>ceil celesti scene cap shelv book second floor...</td>\n",
       "      <td>/places/albertine</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>The Monty Python Foot</td>\n",
       "      <td>hang room nation galleri anoth paint cupid ven...</td>\n",
       "      <td>/places/the-monty-python-foot-london-england</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>'Unsinkable' Molly Brown House</td>\n",
       "      <td>gonna movefrom place placeto find housewith st...</td>\n",
       "      <td>/places/unsinkable-molly-brown-house</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Fraunces Tavern</td>\n",
       "      <td>fraunc tavern origin home earli new york mayor...</td>\n",
       "      <td>/places/fraunces-tavern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "3091              The Athenian Agora   \n",
       "5958                  Old Stone Fort   \n",
       "59          The Witch House of Salem   \n",
       "329                 Uncommon Objects   \n",
       "1086                       Albertine   \n",
       "1134           The Monty Python Foot   \n",
       "1158  'Unsinkable' Molly Brown House   \n",
       "1211                 Fraunces Tavern   \n",
       "\n",
       "                                            Description  \\\n",
       "3091  lie right beneath northern slope acropoli anci...   \n",
       "5958  confluenc big littl duck river near manchest t...   \n",
       "59    salem witchcraft trial took place februari may...   \n",
       "329   like eleg antiqu mall gone horribl wrong diffe...   \n",
       "1086  ceil celesti scene cap shelv book second floor...   \n",
       "1134  hang room nation galleri anoth paint cupid ven...   \n",
       "1158  gonna movefrom place placeto find housewith st...   \n",
       "1211  fraunc tavern origin home earli new york mayor...   \n",
       "\n",
       "                                                   Url  Similarity  \n",
       "3091          /places/the-athenian-agora-athens-greece         1.0  \n",
       "5958  /places/old-stone-fort-state-archaeological-park         1.0  \n",
       "59                           /places/witch-house-salem         1.0  \n",
       "329                           /places/uncommon-objects         1.0  \n",
       "1086                                 /places/albertine         1.0  \n",
       "1134      /places/the-monty-python-foot-london-england         1.0  \n",
       "1158              /places/unsinkable-molly-brown-house         1.0  \n",
       "1211                           /places/fraunces-tavern         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using this second search engine we get as results the k-top best much to our query based on cosine similarity.\n",
    "# If the there is more than one match with same value of this score we ordered the results by their index\n",
    "# (following the order of the website).\n",
    "\n",
    "# It also works with repetition (getting different values of similarity) and stopwords (removing them).\n",
    "\n",
    "search_engine_2(df, 'american museum', 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5wr0dYk_2UM"
   },
   "source": [
    "---\n",
    "## **3. Define a new score!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OQ2GuM3A_2NL"
   },
   "outputs": [],
   "source": [
    "# creating a function that requires as input our dataframe and the query to simulate a search engine\n",
    "\n",
    "def search_engine_3(dataframe, query, country=None, num_people=None, k=10):\n",
    "\n",
    "    descr = dataframe.placeDesc\n",
    "    splitted_rows = descr.apply(lambda row: row.split())\n",
    "    vocabulary = list(set([i for row in splitted_rows for i in set(row)]))\n",
    "    vocabulary.sort()\n",
    "\n",
    "    query_split = query.split()\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stemmers = nltk.stem.SnowballStemmer('english')\n",
    "    stemmed_query = [stemmers.stem(word.lower()) for word in query_split if word not in stopwords]\n",
    "    if not all([word in vocabulary for word in stemmed_query]):\n",
    "        print('Invalid query! Correct your text')\n",
    "        return\n",
    "\n",
    "    id_query_words = [vocabulary.index(word) for word in stemmed_query if word in vocabulary]\n",
    "\n",
    "    inverted_index_1 = pickle.load(open('inverted_index_1.pkl', 'rb'))\n",
    "    docs = [inverted_index_1[str(id)] for id in id_query_words]\n",
    "    all_docs = [word for doc in docs for word in doc]\n",
    "\n",
    "    if all_docs == []:\n",
    "        print('No places found! Try with another query')\n",
    "        return\n",
    "\n",
    "    if country is not None:\n",
    "        all_docs = [match for match in all_docs if string.capwords(country) in df.placeAddress[match]]\n",
    "        if all_docs == []:\n",
    "            print(f'No places found in {country}! Try with another country')\n",
    "            return\n",
    "\n",
    "    people = (df.numPeopleVisited + df.numPeopleWant)\n",
    "    tot_people = sum(people)\n",
    "\n",
    "    if num_people is not None:\n",
    "        if num_people == 'low':\n",
    "            all_docs = [match for match in all_docs if people[match] <= 1000 / tot_people ] \n",
    "            if all_docs == []:\n",
    "                print(\"No places little visited! Try with 'high'\")\n",
    "                return\n",
    "        else:\n",
    "            all_docs = [match for match in all_docs if people[match] > 1000 / tot_people] \n",
    "            if all_docs == []:\n",
    "                print(\"No places much visited! Try with 'low'\")\n",
    "                return\n",
    "    \n",
    "    matches = Counter(all_docs)\n",
    "    final_matches = {}\n",
    "    for place, n_words in matches.items():\n",
    "        final_matches[place] = (n_words, people.loc[place] / tot_people)\n",
    "\n",
    "    final_matches = dict(sorted(final_matches.items(), key=lambda item: item[1], reverse=True))\n",
    "    output = dataframe[['placeName', 'placeDesc', 'placeURL']].loc[list(final_matches.keys())]\n",
    "    output.columns = ['Title', 'Description', 'Url']    \n",
    "    output.isetitem(2, [row[28:] for row in output.Url])\n",
    "    values = list(final_matches.values())\n",
    "    output['Score'] = [score[1] for score in values]\n",
    "    output['Matched_words'] = [score[0] for score in values]\n",
    "    print(f\"\\n Query: {query} \\n\")\n",
    "    display(output[:k])\n",
    "\n",
    "    return list(output.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Query: american museum \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "      <th>Score</th>\n",
       "      <th>Matched_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Horniman Museum and Gardens</td>\n",
       "      <td>horniman museum show uniqu collect sinc focus ...</td>\n",
       "      <td>/places/horniman-museum</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>The Monty Python Foot</td>\n",
       "      <td>hang room nation galleri anoth paint cupid ven...</td>\n",
       "      <td>/places/the-monty-python-foot-london-england</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>Cabaret Mechanical Theatre</td>\n",
       "      <td>theater cabaret exact cabaret mechan theatr co...</td>\n",
       "      <td>/places/cabaret-mechanical-theatre</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>PsychoBarn</td>\n",
       "      <td>casual stroll piccadilli shop regent street mi...</td>\n",
       "      <td>/places/psychobarn</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Natural History Museum of London</td>\n",
       "      <td>establish natur histori museum london impress ...</td>\n",
       "      <td>/places/natural-history-museum</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Viktor Wynd Museum of Curiosities, Fine Ar...</td>\n",
       "      <td>viktor littl shop horror last tuesday societi ...</td>\n",
       "      <td>/places/the-viktor-wynd-museum-of-curiosities-...</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>221b Baker Street</td>\n",
       "      <td>christma annual huge popular victorian literar...</td>\n",
       "      <td>/places/221b-baker-street</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>The Churchill War Rooms</td>\n",
       "      <td>hidden deep underneath street westminst lie on...</td>\n",
       "      <td>/places/the-churchill-war-rooms-london-england</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Magic Circle Museum</td>\n",
       "      <td>establish back magic circl secret group illusi...</td>\n",
       "      <td>/places/magic-circle-museum</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Wellcome Collection &amp; Library</td>\n",
       "      <td>born wisconsin five year state incorpor union ...</td>\n",
       "      <td>/places/wellcome-collection-library</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Kensal Green Cemetery and Catacombs</td>\n",
       "      <td>kensal green one oldest public burial ground f...</td>\n",
       "      <td>/places/kensal-green-cemetery-and-catacombs</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>The Imperial War Museum London</td>\n",
       "      <td>imperi war museum poignant move memori great i...</td>\n",
       "      <td>/places/the-imperial-war-museum-london-london-...</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>The Mail Rail</td>\n",
       "      <td>post offic known automat electr railway creat ...</td>\n",
       "      <td>/places/the-mail-rail-london-england</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "985                         Horniman Museum and Gardens   \n",
       "1134                              The Monty Python Foot   \n",
       "2656                         Cabaret Mechanical Theatre   \n",
       "5862                                         PsychoBarn   \n",
       "218                    Natural History Museum of London   \n",
       "40    The Viktor Wynd Museum of Curiosities, Fine Ar...   \n",
       "153                                   221b Baker Street   \n",
       "152                             The Churchill War Rooms   \n",
       "109                                 Magic Circle Museum   \n",
       "396                       Wellcome Collection & Library   \n",
       "170                 Kensal Green Cemetery and Catacombs   \n",
       "1298                     The Imperial War Museum London   \n",
       "223                                       The Mail Rail   \n",
       "\n",
       "                                            Description  \\\n",
       "985   horniman museum show uniqu collect sinc focus ...   \n",
       "1134  hang room nation galleri anoth paint cupid ven...   \n",
       "2656  theater cabaret exact cabaret mechan theatr co...   \n",
       "5862  casual stroll piccadilli shop regent street mi...   \n",
       "218   establish natur histori museum london impress ...   \n",
       "40    viktor littl shop horror last tuesday societi ...   \n",
       "153   christma annual huge popular victorian literar...   \n",
       "152   hidden deep underneath street westminst lie on...   \n",
       "109   establish back magic circl secret group illusi...   \n",
       "396   born wisconsin five year state incorpor union ...   \n",
       "170   kensal green one oldest public burial ground f...   \n",
       "1298  imperi war museum poignant move memori great i...   \n",
       "223   post offic known automat electr railway creat ...   \n",
       "\n",
       "                                                    Url     Score  \\\n",
       "985                             /places/horniman-museum  0.000224   \n",
       "1134       /places/the-monty-python-foot-london-england  0.000183   \n",
       "2656                 /places/cabaret-mechanical-theatre  0.000099   \n",
       "5862                                 /places/psychobarn  0.000061   \n",
       "218                      /places/natural-history-museum  0.000740   \n",
       "40    /places/the-viktor-wynd-museum-of-curiosities-...  0.000543   \n",
       "153                           /places/221b-baker-street  0.000536   \n",
       "152      /places/the-churchill-war-rooms-london-england  0.000508   \n",
       "109                         /places/magic-circle-museum  0.000363   \n",
       "396                 /places/wellcome-collection-library  0.000355   \n",
       "170         /places/kensal-green-cemetery-and-catacombs  0.000348   \n",
       "1298  /places/the-imperial-war-museum-london-london-...  0.000343   \n",
       "223                /places/the-mail-rail-london-england  0.000320   \n",
       "\n",
       "      Matched_words  \n",
       "985               2  \n",
       "1134              2  \n",
       "2656              2  \n",
       "5862              2  \n",
       "218               1  \n",
       "40                1  \n",
       "153               1  \n",
       "152               1  \n",
       "109               1  \n",
       "396               1  \n",
       "170               1  \n",
       "1298              1  \n",
       "223               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For num_people use { 'high' , 'low' }. The treshold is 1000 that is the sum of people that will be or that have already been there\n",
    "\n",
    "search_engine_3(df, 'american museum', country='england', num_people='high', k=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiNoRx2N_2Gl"
   },
   "source": [
    "---\n",
    "## **4. Visualizing the most relevant places**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdDCiAtw_1_F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVU1bG3jAR0Z"
   },
   "source": [
    "---\n",
    "## **5. BONUS: More complex search engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKiknB6eARtR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7Hd6BgYARmn"
   },
   "source": [
    "---\n",
    "## **6. Command line question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IlihMLkKARe-",
    "outputId": "4007975a-d0db-47d4-d479-0188407e9c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country :  Italy\n",
      "Number of places that can be found in Italy : 182\n",
      "Average visit of the places of Italy : 377.02197802197804\n",
      "People that want to visit the places of England : 152541\n",
      "Country :  Spain\n",
      "Number of places that can be found in Spain : 81\n",
      "Average visit of the places of Spain : 474.98765432098764\n",
      "People that want to visit the places of England : 63980\n",
      "Country :  France\n",
      "Number of places that can be found in France : 188\n",
      "Average visit of the places of France : 431.15425531914894\n",
      "People that want to visit the places of England : 189646\n",
      "Country :  England\n",
      "Number of places that can be found in England : 364\n",
      "Average visit of the places of England : 475.97527472527474\n",
      "People that want to visit the places of England : 386670\n",
      "Country :  United States\n",
      "Number of places that can be found in United States : 4239\n",
      "Average visit of the places of United States : 430.11512149091766\n",
      "People that want to visit the places of England : 3959796\n"
     ]
    }
   ],
   "source": [
    "# We make sure with a python script that the output of the bash script is good\n",
    "# In the output of the bash script, we can't have floats because arithmetic operators don't return floats\n",
    "\n",
    "df_out = pd.read_csv(os.getcwd()+'/locations_data.tsv', sep='\\t', usecols=['numPeopleVisited', 'numPeopleWant', 'placeAddress'])\n",
    "\n",
    "countries = ['Italy', 'Spain', 'France', 'England', 'United States']\n",
    "\n",
    "for country in countries :\n",
    "    n_places = len(df_out[df_out['placeAddress'].str.contains(country) == True])\n",
    "    print(\"Country : \",country)\n",
    "    print(\"Number of places that can be found in \"+country+\" : \"+str(n_places))\n",
    "    print(f\"Average visit of the places of {country} : \"+str(sum(df_out[df_out['placeAddress'].str.contains(country) == True].numPeopleVisited)/n_places))\n",
    "    print(\"People that want to visit the places of England : \"+str(sum(df_out[df_out['placeAddress'].str.contains(country) == True].numPeopleWant)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_eW_Q1-ARH1"
   },
   "source": [
    "---\n",
    "## **7. Theoretical question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0P8LDEG4ARBq"
   },
   "outputs": [],
   "source": [
    "with open('ApplicantsInfo.txt', 'x') as f:\n",
    "    url = f'https://adm2022.s3.amazonaws.com/ApplicantsInfo.txt'\n",
    "    result = requests.get(url)\n",
    "    soup = bs(result.text)\n",
    "    s = soup.find_all('body')\n",
    "    print(s)\n",
    "    f.write(str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMj-qt5egkLm"
   },
   "outputs": [],
   "source": [
    "Application = pd.read_csv('ApplicantsInfo.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rru41XUtgkLn"
   },
   "outputs": [],
   "source": [
    "n =Application.iloc[0]\n",
    "Application.drop(0, inplace=True)\n",
    "N= int(n[0][10:15])\n",
    "M= int(n[0][16:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8lzuSDMgkLn"
   },
   "outputs": [],
   "source": [
    "df_average = pd.DataFrame(columns=('names','surnames','averages'))\n",
    "for i in range(N):\n",
    "    name = Application.iloc[i][0].split(' ')[0]\n",
    "    surname = Application.iloc[i][0].split(' ')[1]\n",
    "    all_points = Application.iloc[i][0].split(' ')[2:]\n",
    "    count = 0\n",
    "    for i in all_points:\n",
    "        s = int(i)\n",
    "        count += s\n",
    "    average = round(count/M,2)\n",
    "    df_average.loc[i]=[name, surname, average]\n",
    "    \n",
    "df_average.head()\n",
    "df_average.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nihakLsugkLo"
   },
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i in tqdm(range(N)):\n",
    "    name = Application.iloc[i][0].split(' ')[0]\n",
    "    surname = Application.iloc[i][0].split(' ')[1]\n",
    "    all_points = Application.iloc[i][0].split(' ')[2:]\n",
    "    count = 0\n",
    "    for i in all_points:\n",
    "        s = int(i)\n",
    "        count += s\n",
    "    average = round(count/M,2)\n",
    "    lista.append((name, surname, average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOCKNZaXgkLo"
   },
   "source": [
    "####  BubbleSort( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S04aiNcEgkLo"
   },
   "outputs": [],
   "source": [
    "def BubbleSort(lista):\n",
    "    for i in tqdm(range(N)):  #N\n",
    "        for j in range(i):  #i\n",
    "            if lista[j][2] >= lista[j+1][2]:  #1\n",
    "                if lista[j][2] == lista[j+1][2]:  #1\n",
    "                    if lista[j][0] >= lista[j+1][0]:  #1\n",
    "                        if lista[j][0] == lista[j+1][0]:  #1\n",
    "                            if lista[j][1] > lista[j+1][1]: #1 \n",
    "                                lista[j],lista[j+1]=lista[j+1],lista[j]  #1\n",
    "                        else:\n",
    "                            lista[j],lista[j+1]=lista[j+1],lista[j]  #1\n",
    "                else:\n",
    "                    lista[j],lista[j+1]=lista[j+1],lista[j]  #1\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpWbkVbXgkLo"
   },
   "outputs": [],
   "source": [
    "BubbleSort(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJcOWQ30gkLp"
   },
   "source": [
    "#### MergeSort( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUppC8jBgkLp"
   },
   "outputs": [],
   "source": [
    "def Merge(l1,l2):\n",
    "    n=len(l1)\n",
    "    m=len(l2)\n",
    "    lista=[]\n",
    "    i=0\n",
    "    j=0\n",
    "    while i < n and j < m:\n",
    "        if l1[i][2] <= l2[j][2]:\n",
    "            if l1[i][2] == l2[j][2]:\n",
    "                if l1[i][0] <= l2[j][0]:\n",
    "                    if l1[i][0] == l2[j][0]:\n",
    "                        if l1[i][1] < l2[j][1]:\n",
    "                            lista.append(l1[i])\n",
    "                            i+=1\n",
    "                        else:\n",
    "                            lista.append(l2[j])\n",
    "                            j+=1\n",
    "                    else:\n",
    "                        lista.append(l1[i])\n",
    "                        i+=1\n",
    "                else:\n",
    "                    lista.append(l2[j])\n",
    "                    j+=1\n",
    "            else:\n",
    "                lista.append(l1[i])\n",
    "                i+=1\n",
    "                \n",
    "        else:\n",
    "            lista.append(l2[j])\n",
    "            j+=1\n",
    "\n",
    "    while i < n:\n",
    "            lista.append(l1[i])\n",
    "            i += 1\n",
    "    while j < m:\n",
    "            lista.append(l2[j])\n",
    "            j += 1\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYvJJGhagkLp"
   },
   "outputs": [],
   "source": [
    "def MergeSort(lista):\n",
    "    if len(lista) == 1:\n",
    "        return lista\n",
    "    else:\n",
    "        lista1=lista[:len(lista)//2]\n",
    "        lista2=lista[len(lista)//2:]\n",
    "        l1=MergeSort(lista1)\n",
    "        l2=MergeSort(lista2)\n",
    "        return Merge(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIS543K7gkLq"
   },
   "outputs": [],
   "source": [
    "MergeSort(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYL-zMpwgkLq"
   },
   "source": [
    "#### QuickSort( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnLqVJbLgkLq"
   },
   "outputs": [],
   "source": [
    "\n",
    "def QuickSort(lista):\n",
    "    if len(lista) <= 1:\n",
    "        return lista\n",
    "    else:\n",
    "        pivot = rdm.choice(lista)\n",
    "        lista.remove(pivot)\n",
    "        l1=[]\n",
    "        l2=[]\n",
    "        for x in lista:\n",
    "            if x[2] <= pivot[2]:\n",
    "                if x[2] == pivot[2]:\n",
    "                    if x[0] <= pivot[0]:\n",
    "                        if x[0] == pivot[0]:\n",
    "                            if x[1] < pivot[1]:\n",
    "                                l1.append(x)\n",
    "                            else:\n",
    "                                l2.append(x)\n",
    "                        else:\n",
    "                            l1.append(x)\n",
    "                    else:\n",
    "                        l2.append(x)\n",
    "                else:\n",
    "                    l1.append(x)\n",
    "            else:\n",
    "                l2.append(x)\n",
    "        l= QuickSort(l1)+[pivot]+ QuickSort(l2)\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVC8gT_VgkLq"
   },
   "outputs": [],
   "source": [
    "QuickSort(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BubbleSort\n",
    "\n",
    "The BubbleSort algorithm beacome with a for loop in range $N$ \n",
    "and for every iteration do another for loop in range $i$ where $i$ ranges forom 0 to $N$. \n",
    "Every iteration do only if statement(for up to 5 times) that have costant runnig time($C_1,C_2,C_3,C_4,C_5$). When this condition do something, they invert the 2 position , that have a costant running time($C_6$). In formula:\n",
    "\n",
    "$T(N)=N\\times i(C_1+C_2+C_3+C_4+C_5+C_6)=O(N)\\times O(N)\\times (O(1))=O(N^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MergeSort\n",
    "\n",
    "The MergeSort algorithm call the Merge function, so first have a look to Merge runnnig time:\n",
    "Merge has two ordered list as imput and return a ordered list.\n",
    "Start definig the length of the 2 list, define the new list, and creat 2 counters, all this operation have costant runnig time($C_1$).\n",
    "Now start with a while loop, that end when $i$ or $j$ become $n$ or $m$(the length of the 2 imput lists) respectively. Note that in the end of every iteration of this while loop, only one of the 2 contators($i,j$), increse. afther this while, there are other 2 while, only one of this will be executed it \"finish\" the one of the lists not accomplished in the firt while.\n",
    "Therefore this 3 while have in total $n+m$ running time.\n",
    "\n",
    "$$T_{Merge}(N)=T_{Merge}(n+m)=C_1+(n+m)=O(1)+O(n+m)=O(n+m)=O(N)$$\n",
    "\n",
    "Now, we can go back to the Sort algorithm a recursive algorithm, which has as imput a list(with length $N$). The initial contition have costant running time($C_1$) and after we define 2 list($C_2$), we do two recursive calls of the two list(with lengths $\\frac{N}{2}$), and we return with Merge function.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "T_{MSort}(N)=\n",
    "\\begin{cases}\n",
    "C_1, & \\text{if $N=1$,} \\\\\n",
    "C_2T_{Merge}(N)+2T_{MSort}(\\frac{N}{2}), & \\text{if $N > 1$.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Let's see when $N > 1$:\n",
    "\n",
    "$T_{MSort}(N)=C_2T_{Merge}(N)+2T_{MSort}(\\frac{N}{2})=C_2 N+ 2T_{MSort}(\\frac{N}{2})=$\n",
    "\n",
    "$=C_2 N + 2\\left[C_2\\frac{N}{2} + 2T_{MSort}(\\frac{N}{4}) \\right]=C_2 N + C_2 N + 4T_{MSort}(\\frac{N}{4})= $\n",
    "\n",
    "$=C_2 N + C_2 N + 4\\left[C_2\\frac{N}{4}+ 2T_{MSort}(\\frac{N}{8})\\right]=$\n",
    "\n",
    "$=C_2 N + C_2 N + C_2 N + 8T_{MSort}(\\frac{N}{8})=$\n",
    "\n",
    "$...$\n",
    "\n",
    "$=i C_2 N + 2^iT_{MSort}(\\frac{N}{2^i})=$\n",
    "\n",
    "$\\text{For   } i = \\log_2 N, \\text{we have}: 2^i=2^{ \\log_2 N}=N\\text{   therefore, with a sostitution:}    $\n",
    "\n",
    "$=C_2 N \\log_2 N  + N T_{MSort}(1)=$\n",
    "\n",
    "$=C_2 N \\log_2 N  + N C_1= O(1)O(N)O(\\log_2 N)+ O(1)O(N)$\n",
    "\n",
    "$=O(N \\log_2 N)+ O(N)=O(N\\log_2 N)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QuickSort\n",
    "\n",
    "The QuickSort is also a recurvise function wich has as imput a list. start with initial condition that have costant runnig time ($C_1$), afther define 2 list and a pivot($C_2$), remuve it to the list(worst case $O(n)$),  and start a for loop in range $N$(the length of the imput list). for every iteration(for every element of the list), with an if chain(costant time) put the element of the list in the one or the second list previously declared rispectively if the element is lower or bigger than the pivot.\n",
    "We need all this case of if condition becose the element of the list are Triple, so we decide to sort first for the last parameter(the averege),afther for the alfabetic order, respectively name(first parameter), and surname(second parameter). that's not a big problem for the computation, because the chain of if has also costant running time($C_3$), and in the end of every iteration we will only have one assignment($C_4$).\n",
    "\n",
    "$$\n",
    "T(n)=\n",
    "\\begin{cases}\n",
    "C_1, & \\text{if $n = 1$,} \\\\\n",
    "C_2+T_{remuve}(n)+C_3+C_4+T(n-i)+T(i), & \\text{if $n > 1$.}\n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\begin{cases}\n",
    "C_1, & \\text{if $n = 1$,} \\\\\n",
    "O(n)+ O(1)+T(N-i)+T(i), & \\text{if $n > 1$.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Let's look at this term:  $T(n-i)+T(i)$   separately:\n",
    "$i$ is random, so in the very best case $i$ is always in the center of the imput list, so we have: $T(n-\\frac{n}{2})+T(\\frac{n}{2})=2T(\\frac{n}{2})= O(\\log_2 n)$ \n",
    "\n",
    "But in the very worts case we have $i$ at the ends of the range, if is 1, at the start we will have $T(n-1)+T(1)$ were $T(1)$ have costant running time, if is $n-1$ in the end we will have $T(n-(n-1))+T(n-1)=T(1)+T(n-1)=O(n)$\n",
    "\n",
    "therefore we can write:\n",
    "\n",
    "$ O(\\log_2 n) \\leq T(n-i)+T(i) \\leq  O(n) $\n",
    "\n",
    "According that $T_{remuve}(n)$ is a $O(n)$ for the list, we can write:\n",
    "\n",
    "$ O(n)O(\\log_2 n) \\leq T(n) \\leq  O(n)O(n) $\n",
    "\n",
    "$O(n \\log_2 n) \\leq T(n) \\leq  O(n^2) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "773286f42bdafd8588749582ed653d25b280a530e585f5f155cb0082e5f8cdaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
