{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f10b99f",
   "metadata": {},
   "source": [
    "# Begin of ADM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00f0789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca38d01",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110bebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('Places_url.txt', 'x') as f:\n",
    "    for i in tqdm(range(1,401)):             \n",
    "        url = f'https://www.atlasobscura.com/places?page={i}&sort=likes_count'\n",
    "        result = requests.get(url)\n",
    "        soup = BeautifulSoup(result.text)\n",
    "        matches = soup.find_all(\"a\", {\"class\": \"content-card content-card-place\"})\n",
    "        for match in matches:\n",
    "            f.write(match['href'] + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac183e",
   "metadata": {},
   "source": [
    "### 1.2. Crawl places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(f'Locations')\n",
    "places_url = pd.read_csv('Places_url.txt', header=None)\n",
    "\n",
    "\n",
    "for page in tqdm(range(0,400)):\n",
    "    os.mkdir(f'Locations/page_{page + 1}')\n",
    "    for loc in range(0,18):\n",
    "        with open(f'Locations/page_{page + 1}/location_{(18 * page) + loc + 1}.html', 'x', encoding=\"utf-8\") as f:\n",
    "            url = 'https://www.atlasobscura.com' + places_url.iloc[(18 * page) + loc][0]\n",
    "            result = requests.get(url)\n",
    "            html = result.text\n",
    "            f.write(html)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811aa60",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf3352bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTMLFile = open(f'Locations/page_1/location_2.html', \"r\", encoding=\"utf-8\")\n",
    "index = HTMLFile.read()\n",
    "soup = BeautifulSoup(index, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# put it on the 'import' cell â˜º\n",
    "# and please check BeautifulSoup or bs and put them in the say way\n",
    "# THANKS!\n",
    "\n",
    "\n",
    "# 7)\n",
    "\n",
    "placeNearby = [match.text for match in soup.find_all('div', {'class': 'DDPageSiderailRecirc__item-title'})]\n",
    "\n",
    "    \n",
    "# 8)\n",
    "\n",
    "match = soup.find_all(\"address\", {\"class\":\"DDPageSiderail__address\"})[0]\n",
    "a = match.find('div').contents[0:5:2]\n",
    "placeAddress = \"\".join(a)  \n",
    "\n",
    "\n",
    "# 9)\n",
    "# ask for int but are coordinate are float\n",
    "\n",
    "match = soup.find_all(\"div\", {\"class\":\"DDPageSiderail__coordinates js-copy-coordinates\"})[0].get_text().split()\n",
    "placeAlt = float(match[0][:-1])\n",
    "placeLong = float(match[1])\n",
    "\n",
    "\n",
    "# 10)\n",
    "\n",
    "placeEditors = [match.get('title') for match in soup.find_all(\"div\", {\"class\":\"DDPContributor__icon\"})]\n",
    "    \n",
    "\n",
    "# 11)\n",
    "\n",
    "a = soup.find_all(\"div\", {\"class\":\"DDPContributor__name\"})[0].text\n",
    "placePubDate = datetime.strptime(a, '%B %d, %Y')\n",
    "\n",
    "\n",
    "# 12)\n",
    "    \n",
    "a = soup.find_all('div', {\"data-gtm-template\" : \"DDP Footer Recirc Lists\"})[0]\n",
    "placeRelatedLists = [match.text.strip() for match in a.find_all('h3')]\n",
    "    \n",
    "\n",
    "# 13)\n",
    "\n",
    "matches = soup.find_all(\"a\", {\"class\":\"Card --content-card-v2 --content-card-item\"})\n",
    "placeRelatedPlaces = [match['href'] for match in matches[4:8]]\n",
    "    \n",
    "    \n",
    "# 14)\n",
    "\n",
    "placeURL = soup.find_all(\"link\", {'rel':'canonical'})[0]['href']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
